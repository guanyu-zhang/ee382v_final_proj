{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, classification_report, accuracy_score \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.random import set_seed\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import np_utils\n",
    "import check_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivar_transform(value, standard):\n",
    "    \"\"\"\n",
    "    parms:\n",
    "    value: input label\n",
    "    standard: the label that is preserved, all other labels are set to be 'other'\n",
    "    standrd is in {'1', '2', 'b', 'c', 'm', 'p', 't', 'x'}\n",
    "    \"\"\"\n",
    "    if value != standard:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return standard\n",
    "    \n",
    "def bivar(data, standard):\n",
    "    data_cp = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        temp = bivar_transform(data.iloc[:,-1][i], standard)\n",
    "        data_cp.iloc[:,-1][i] = temp\n",
    "    return data_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.getcwd()\n",
    "dir_list = os.listdir(os.path.join(main_path,'p1'))\n",
    "def lopo(p, standard: str = None):\n",
    "    \"\"\"\n",
    "    LOPO\n",
    "    parms:\n",
    "    p: leave one participant out p in [1,2,3,4,5,6,7]\n",
    "    return: two dictionaries (train, test)\n",
    "    \"\"\"\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    main_list = ['p'+str(i) for i in range(1,8)]\n",
    "    main_list.remove('p'+str(p))\n",
    "    for i in main_list:\n",
    "        for j in dir_list:\n",
    "            d = pd.read_csv(os.path.join(main_path,i,j),low_memory=False)\n",
    "            if standard is not None:\n",
    "                d = bivar(d, standard)\n",
    "            d = np.array(d)\n",
    "            if train_data.get(j) is None:\n",
    "                train_data[j] = d\n",
    "            else:\n",
    "                train_data[j] = np.r_[train_data[j],d]\n",
    "    \n",
    "    for i in dir_list:\n",
    "        d = pd.read_csv(os.path.join(main_path,'p'+str(p),i),low_memory=False)\n",
    "        if standard is not None:\n",
    "            d = bivar(d, standard)\n",
    "        d = np.array(d)\n",
    "        test_data[i] = d\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = lopo(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_data(train_data, test_data):\n",
    "    merged_train, merged_test = [], []\n",
    "    for i in train_data:\n",
    "        if len(merged_train) == 0:\n",
    "            merged_train = train_data[i]\n",
    "            merged_test = test_data[i]\n",
    "        else:\n",
    "            merged_train = np.r_[merged_train,train_data[i]]\n",
    "            merged_test = np.r_[merged_test,test_data[i]]\n",
    "    return merged_train, merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train, merged_test = get_merged_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35259, 1001), (6672, 1001))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merged_train.shape,merged_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           b       0.00      0.00      0.00       0.0\n",
      "           c       0.00      0.00      0.00       0.0\n",
      "       other       0.00      0.00      0.00    6672.0\n",
      "           p       0.00      0.00      0.00       0.0\n",
      "           t       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    6672.0\n",
      "   macro avg       0.00      0.00      0.00    6672.0\n",
      "weighted avg       0.00      0.00      0.00    6672.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(max_depth=10, random_state=0)).fit(merged_train[:,:-1], merged_train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.82      0.83      1615\n",
      "           2       0.32      0.19      0.24       370\n",
      "           b       0.67      0.89      0.77      2095\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.00      0.00      0.00        91\n",
      "           p       0.09      0.01      0.01       132\n",
      "           t       0.81      0.71      0.75      2350\n",
      "           x       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.74      6672\n",
      "   macro avg       0.34      0.33      0.33      6672\n",
      "weighted avg       0.72      0.74      0.72      6672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "merged_test_pred = clf.predict(merged_test[:,:-1])\n",
    "print(classification_report(merged_test[:,-1],merged_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsOneClassifier(RandomForestClassifier(max_depth=12, random_state=0)).fit(merged_train[:,:-1], merged_train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.81      0.84      1615\n",
      "           2       0.41      0.35      0.38       370\n",
      "           b       0.68      0.89      0.77      2095\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.00      0.00      0.00        91\n",
      "           p       0.29      0.02      0.03       132\n",
      "           t       0.82      0.71      0.76      2350\n",
      "           x       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.75      6672\n",
      "   macro avg       0.38      0.35      0.35      6672\n",
      "weighted avg       0.74      0.75      0.73      6672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "merged_test_pred = clf.predict(merged_test[:,:-1])\n",
    "print(classification_report(merged_test[:,-1],merged_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = './'\n",
    "sub_list = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7']\n",
    "feat_size=1000\n",
    "sound_list = []\n",
    "# obtain the path to all csv files\n",
    "for sub in sub_list:\n",
    "    sound_dir = './%s/' % sub\n",
    "    sound_list_sub = [os.path.join(sound_dir, item) \\\n",
    "                      for item in os.listdir(sound_dir) if item.endswith('.csv')]\n",
    "    sound_list.extend(sound_list_sub)\n",
    "    \n",
    "sound_data, groups = [], []   # groups is the subject index for each instance\n",
    "for item in sound_list:\n",
    "    sub_idx = int(item.split('/')[-2][1:])   # item: .../P1/embedding_1s/outdoor_refine.csv, extract x from Px\n",
    "    audio_seg = pd.read_csv(item, delimiter=',', header=None, dtype=str).values\n",
    "    groups.extend([sub_idx] * len(audio_seg))\n",
    "    sound_data.append(audio_seg)\n",
    "sound_data = np.concatenate(sound_data, axis = 0)\n",
    "features, labels = sound_data[:, :feat_size].astype(float), sound_data[:, -1]\n",
    "groups = np.asarray(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "only keep 1,2,x\n",
    "\"\"\"\n",
    "idx_voice = np.where(labels == '1')\n",
    "idx_2voice = np.where(labels == '2')\n",
    "idx_undef = np.where(labels == 'x')\n",
    "labels_voice = labels[idx_voice]\n",
    "labels_2voice = labels[idx_2voice]\n",
    "labels_undef = labels[idx_undef]\n",
    "labels = np.concatenate((labels_voice, labels_2voice, labels_undef))\n",
    "features_voice = features[idx_voice]\n",
    "features_2voice = features[idx_2voice]\n",
    "features_undef = features[idx_undef]\n",
    "features = np.concatenate((features_voice, features_2voice, features_undef))\n",
    "groups_voice = groups[idx_voice]\n",
    "groups_2voice = groups[idx_2voice]\n",
    "groups_undef = groups[idx_undef]\n",
    "groups = np.concatenate((groups_voice, groups_2voice, groups_undef))\n",
    "\n",
    "idx_voice = np.where(labels == '1')   \n",
    "labels[idx_voice] = 0\n",
    "idx_2voice = np.where(labels == '2')   \n",
    "labels[idx_2voice] = 1\n",
    "idx_undef = np.where(labels == 'x')   \n",
    "labels[idx_undef] = 2\n",
    "\n",
    "labels = labels.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= 10\n",
    "features_new = np.empty((0,1000))\n",
    "groups_new = np.empty((0,1))\n",
    "labels_new = np.empty((0,1))\n",
    "for i in range(0, len(labels)-t, t):\n",
    "    # only mean the instances within the same groups(subjects) and ignore ones of the transition\n",
    "    if groups[i] == groups[i+t]:        \n",
    "        temp_feat = features[i:i+t]\n",
    "        # mean for every t seconds\n",
    "        mean_feat = np.mean(temp_feat, axis=0)\n",
    "        #mean_feat = temp_feat\n",
    "        mean_feat = np.reshape(mean_feat, (1,1000))\n",
    "    else:\n",
    "        pass\n",
    "    features_new = np.vstack((features_new, mean_feat))\n",
    "    labels_new = np.vstack((labels_new, labels[i]))\n",
    "    groups_new = np.vstack((groups_new, groups[i]))\n",
    "labels_new = labels_new.astype(int)\n",
    "groups_new = groups_new.reshape((groups_new.shape[0], ))\n",
    "groups_new = groups_new.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def new_unit_data(features, labels, groups, t):\n",
    "#     t= 10\n",
    "#     features_new = np.empty((0,1000))\n",
    "#     groups_new = np.empty((0,1))\n",
    "#     labels_new = np.empty((0,1))\n",
    "#     for i in range(0, len(labels)-t, t):\n",
    "#         # only mean the instances within the same groups(subjects) and ignore ones of the transition\n",
    "#         if features[i] == features[i+t]:        \n",
    "#             temp_feat = features[i:i+t]\n",
    "#             # mean for every t seconds\n",
    "#             mean_feat = np.mean(temp_feat, axis=0)\n",
    "#             #mean_feat = temp_feat\n",
    "#             mean_feat = np.reshape(mean_feat, (1,1000))\n",
    "#         else:\n",
    "#             pass\n",
    "#         features_new = np.vstack((features_new, mean_feat))\n",
    "#         labels_new = np.vstack((labels_new, labels[i]))\n",
    "#         groups_new = np.vstack((groups_new, groups[i]))\n",
    "#     labels_new = labels_new.astype(int)\n",
    "#     groups_new = groups_new.reshape((groups_new.shape[0], ))\n",
    "#     groups_new = groups_new.astype(int)\n",
    "#     return features_new, labels_new, groups_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_nn():\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    def model(self):    \n",
    "        model = Sequential()\n",
    "        model.add(L.Conv2D(64, strides=2, kernel_size=4, activation='relu', padding='same', input_shape=self.input_shape))\n",
    "        model.add(L.Conv2D(128, strides=2, kernel_size=4, activation='relu', padding='same'))\n",
    "        model.add(L.Conv2D(256, strides=2, kernel_size=4, activation='relu', padding='same'))\n",
    "        model.add(L.Conv2D(512, strides=2, kernel_size=4, activation='relu', padding='same'))\n",
    "        model.add(L.Flatten())\n",
    "        model.add(L.Dense(1024, activation='relu'))\n",
    "        model.add(L.Dropout(0.2))\n",
    "        model.add(L.Dense(128, activation='relu'))\n",
    "        model.add(L.Dropout(0.2))\n",
    "        model.add(L.Dense(3, activation='sigmoid'))\n",
    "    \n",
    "        # Compile the model\n",
    "        opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                      optimizer=opt,\n",
    "                      metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_4chars(x):    \n",
    "    return(int(x.split('/')[-1].split('-')[0][4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1476, 1000), (1476, 1), (1476,))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_new.shape, labels_new.shape, groups_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 887, 1: 536, 2: 53})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_new.reshape((1,-1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resample to balance data\n",
    "\"\"\"\n",
    "concat_data = np.c_[features_new, labels_new, groups_new]\n",
    "concat_1 = concat_data[concat_data[:,-2]==0]\n",
    "concat_1 = resample(concat_1, n_samples=500, random_state=0)\n",
    "concat_2 = concat_data[concat_data[:,-2]==1]\n",
    "concat_2 = resample(concat_2, n_samples=500, random_state=0)\n",
    "concat_x = concat_data[concat_data[:,-2]==2]\n",
    "concat_x = resample(concat_x, n_samples=500, random_state=0)\n",
    "concat_data = np.concatenate((concat_1,concat_2,concat_x))\n",
    "features_new = concat_data[:,:-2]\n",
    "labels_new = concat_data[:,-2]\n",
    "groups_new = concat_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(data):\n",
    "    new_data = []\n",
    "    for i in data:\n",
    "        temp_data = i.reshape((25,40,1))\n",
    "        new_data.append(temp_data)\n",
    "    return np.asarray(new_data,dtype=np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 - 6s - loss: 1.0850 - categorical_accuracy: 0.4220 - val_loss: 1.0698 - val_categorical_accuracy: 0.4671\n",
      "Epoch 2/5\n",
      "73/73 - 6s - loss: 0.8898 - categorical_accuracy: 0.5806 - val_loss: 0.7807 - val_categorical_accuracy: 0.3413\n",
      "Epoch 3/5\n",
      "73/73 - 6s - loss: 0.6883 - categorical_accuracy: 0.6492 - val_loss: 0.8767 - val_categorical_accuracy: 0.4731\n",
      "Epoch 4/5\n",
      "73/73 - 6s - loss: 0.5983 - categorical_accuracy: 0.7033 - val_loss: 1.1653 - val_categorical_accuracy: 0.4042\n",
      "Epoch 5/5\n",
      "73/73 - 5s - loss: 0.5045 - categorical_accuracy: 0.7744 - val_loss: 1.2373 - val_categorical_accuracy: 0.5090\n",
      "Epoch 1/5\n",
      "76/76 - 6s - loss: 1.0830 - categorical_accuracy: 0.4312 - val_loss: 1.1260 - val_categorical_accuracy: 0.3902\n",
      "Epoch 2/5\n",
      "76/76 - 5s - loss: 0.9198 - categorical_accuracy: 0.5829 - val_loss: 0.8190 - val_categorical_accuracy: 0.4007\n",
      "Epoch 3/5\n",
      "76/76 - 5s - loss: 0.7072 - categorical_accuracy: 0.6348 - val_loss: 0.8657 - val_categorical_accuracy: 0.4042\n",
      "Epoch 4/5\n",
      "76/76 - 5s - loss: 0.6274 - categorical_accuracy: 0.6727 - val_loss: 0.8178 - val_categorical_accuracy: 0.4042\n",
      "Epoch 5/5\n",
      "76/76 - 5s - loss: 0.5386 - categorical_accuracy: 0.7312 - val_loss: 0.7987 - val_categorical_accuracy: 0.4390\n",
      "Epoch 1/5\n",
      "79/79 - 6s - loss: 1.0874 - categorical_accuracy: 0.4200 - val_loss: 1.0721 - val_categorical_accuracy: 0.5210\n",
      "Epoch 2/5\n",
      "79/79 - 6s - loss: 0.9217 - categorical_accuracy: 0.5626 - val_loss: 0.7148 - val_categorical_accuracy: 0.5714\n",
      "Epoch 3/5\n",
      "79/79 - 5s - loss: 0.7289 - categorical_accuracy: 0.6078 - val_loss: 0.7282 - val_categorical_accuracy: 0.5420\n",
      "Epoch 4/5\n",
      "79/79 - 5s - loss: 0.6461 - categorical_accuracy: 0.6561 - val_loss: 0.6765 - val_categorical_accuracy: 0.6345\n",
      "Epoch 5/5\n",
      "79/79 - 5s - loss: 0.5732 - categorical_accuracy: 0.7171 - val_loss: 0.6694 - val_categorical_accuracy: 0.6218\n",
      "Epoch 1/5\n",
      "87/87 - 6s - loss: 1.0858 - categorical_accuracy: 0.4212 - val_loss: 1.0859 - val_categorical_accuracy: 0.4146\n",
      "Epoch 2/5\n",
      "87/87 - 6s - loss: 0.8904 - categorical_accuracy: 0.5701 - val_loss: 0.8604 - val_categorical_accuracy: 0.3089\n",
      "Epoch 3/5\n",
      "87/87 - 6s - loss: 0.6826 - categorical_accuracy: 0.6187 - val_loss: 0.8158 - val_categorical_accuracy: 0.3659\n",
      "Epoch 4/5\n",
      "87/87 - 6s - loss: 0.6217 - categorical_accuracy: 0.6696 - val_loss: 0.9113 - val_categorical_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "87/87 - 6s - loss: 0.5798 - categorical_accuracy: 0.6761 - val_loss: 0.7589 - val_categorical_accuracy: 0.3821\n",
      "Epoch 1/5\n",
      "79/79 - 6s - loss: 1.0860 - categorical_accuracy: 0.4571 - val_loss: 1.1059 - val_categorical_accuracy: 0.2875\n",
      "Epoch 2/5\n",
      "79/79 - 5s - loss: 0.8685 - categorical_accuracy: 0.5722 - val_loss: 1.1795 - val_categorical_accuracy: 0.3167\n",
      "Epoch 3/5\n",
      "79/79 - 7s - loss: 0.6536 - categorical_accuracy: 0.6524 - val_loss: 1.1665 - val_categorical_accuracy: 0.4250\n",
      "Epoch 4/5\n",
      "79/79 - 6s - loss: 0.5931 - categorical_accuracy: 0.6706 - val_loss: 1.8230 - val_categorical_accuracy: 0.3458\n",
      "Epoch 5/5\n",
      "79/79 - 6s - loss: 0.5059 - categorical_accuracy: 0.7421 - val_loss: 2.0810 - val_categorical_accuracy: 0.3583\n",
      "Epoch 1/5\n",
      "86/86 - 6s - loss: 1.0813 - categorical_accuracy: 0.4109 - val_loss: 0.9937 - val_categorical_accuracy: 0.7591\n",
      "Epoch 2/5\n",
      "86/86 - 6s - loss: 0.8504 - categorical_accuracy: 0.5591 - val_loss: 0.7909 - val_categorical_accuracy: 0.5839\n",
      "Epoch 3/5\n",
      "86/86 - 6s - loss: 0.6683 - categorical_accuracy: 0.6126 - val_loss: 1.2547 - val_categorical_accuracy: 0.4307\n",
      "Epoch 4/5\n",
      "86/86 - 6s - loss: 0.6116 - categorical_accuracy: 0.6581 - val_loss: 0.9256 - val_categorical_accuracy: 0.5547\n",
      "Epoch 5/5\n",
      "86/86 - 6s - loss: 0.5341 - categorical_accuracy: 0.7197 - val_loss: 0.8496 - val_categorical_accuracy: 0.7007\n",
      "Epoch 1/5\n",
      "85/85 - 8s - loss: 1.0893 - categorical_accuracy: 0.3635 - val_loss: 1.1299 - val_categorical_accuracy: 0.2766\n",
      "Epoch 2/5\n",
      "85/85 - 7s - loss: 0.9415 - categorical_accuracy: 0.5151 - val_loss: 0.7489 - val_categorical_accuracy: 0.7234\n",
      "Epoch 3/5\n",
      "85/85 - 6s - loss: 0.7119 - categorical_accuracy: 0.5990 - val_loss: 0.5921 - val_categorical_accuracy: 0.7518\n",
      "Epoch 4/5\n",
      "85/85 - 6s - loss: 0.6393 - categorical_accuracy: 0.6564 - val_loss: 0.6105 - val_categorical_accuracy: 0.6950\n",
      "Epoch 5/5\n",
      "85/85 - 8s - loss: 0.5353 - categorical_accuracy: 0.7388 - val_loss: 0.5672 - val_categorical_accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "seed(0)\n",
    "# keras seed\n",
    "set_seed(0)\n",
    "#features_new = np.expand_dims(features_new, axis=-1).astype(float)\n",
    "#%%\n",
    "          \n",
    "NN = True\n",
    "if NN:\n",
    "    predict = False\n",
    "    save_model_path = './models_resample/'\n",
    "    check_dirs.check_dir(save_model_path)\n",
    "    batch_size = 16\n",
    "    lppo = LeavePGroupsOut(n_groups=1)\n",
    "    #lppo = GroupKFold(n_splits=2)\n",
    "    #kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)\n",
    "    fold_no = 1\n",
    "    f1_per_fold, acc_per_fold, pre_per_fold, rec_per_fold = [], [], [], []\n",
    "    # training\n",
    "    if not predict:\n",
    "        #for train, test in kfold.split(features, labels):\n",
    "        for train, test in lppo.split(features_new, labels_new, groups_new):\n",
    "            feat_train, labels_train = features_new[train], labels_new[train]\n",
    "            feat_test, labels_test = features_new[test], labels_new[test]\n",
    "            feat_train = format_input(feat_train)\n",
    "            feat_test = format_input(feat_test)\n",
    "            labels_train = np_utils.to_categorical(labels_train)\n",
    "            labels_test = np_utils.to_categorical(labels_test)\n",
    "            model_fold = model_nn(input_shape=(25, 40, 1)).model()\n",
    "            # Fit data to model, only models with the best val acc (unbalanced) are saved\n",
    "            model_fold.fit(feat_train, labels_train,\n",
    "                           batch_size=batch_size,\n",
    "                           epochs=5,\n",
    "                           validation_data=(feat_test, labels_test),\n",
    "                           verbose=2,\n",
    "                           callbacks=[K.callbacks.ModelCheckpoint(save_model_path+\"fold%01d-epoch_{epoch:02d}-acc_{val_categorical_accuracy:.4f}.h5\" %fold_no, \n",
    "                                                                  monitor='val_categorical_accuracy', \n",
    "                                                                  verbose=0, \n",
    "                                                                  save_best_only=True, \n",
    "                                                                  save_weights_only=True, \n",
    "                                                                  mode='auto', \n",
    "                                                                  save_freq='epoch')])\n",
    "            del model_fold\n",
    "            fold_no = fold_no + 1\n",
    "    # validation                     \n",
    "    if predict:\n",
    "        models = sorted([os.path.join(save_model_path, item) \\\n",
    "                         for item in os.listdir(save_model_path) if item.endswith('.h5')], key=last_4chars)\n",
    "        #for train, test in kfold.split(features, labels):\n",
    "        for train, test in lppo.split(features_new, labels_new, groups=groups_new):\n",
    "#             feat_train, labels_train = features_new[train], labels_new[train]\n",
    "            feat_test, labels_test = features_new[test], labels_new[test]\n",
    "            feat_test = format_input(feat_test)\n",
    "            labels_test = np_utils.to_categorical(labels_test)\n",
    "            model_pred = model_nn(input_shape=(25, 40, 1)).model()\n",
    "            model_pred.load_weights(models[fold_no - 1])\n",
    "            # prediction\n",
    "            pred_prob = model_pred.predict(feat_test)\n",
    "            # set threshold for binary classification\n",
    "            idx_p = np.where(pred_prob > 0.5)\n",
    "            idx_n = np.where(pred_prob <= 0.5)\n",
    "            pred_prob[idx_p] = 1\n",
    "            pred_prob[idx_n] = 0\n",
    "\n",
    "            acc_per_fold.append(balanced_accuracy_score(labels_test, pred_prob) * 100)\n",
    "            f1_per_fold.append(f1_score(labels_test, pred_prob, average = 'macro') * 100)  \n",
    "            # initialize\n",
    "            del model_pred\n",
    "            fold_no = fold_no + 1\n",
    "        f1 = np.mean(f1_per_fold)\n",
    "        acc = np.mean(acc_per_fold)\n",
    "        print('acc: ', acc, '\\n f1: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70        91\n",
      "           1       0.14      0.06      0.09       124\n",
      "           2       0.51      0.52      0.52       119\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       334\n",
      "   macro avg       0.40      0.51      0.43       334\n",
      "weighted avg       0.38      0.47      0.41       334\n",
      " samples avg       0.47      0.47      0.47       334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82        51\n",
      "           1       0.34      0.94      0.50        79\n",
      "           2       0.00      0.00      0.00       157\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       287\n",
      "   macro avg       0.35      0.64      0.44       287\n",
      "weighted avg       0.22      0.43      0.28       287\n",
      " samples avg       0.43      0.43      0.43       287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        62\n",
      "           1       0.87      0.63      0.73        95\n",
      "           2       0.67      0.89      0.76        81\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       238\n",
      "   macro avg       0.85      0.83      0.83       238\n",
      "weighted avg       0.83      0.81      0.81       238\n",
      " samples avg       0.81      0.81      0.81       238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80        49\n",
      "           1       0.89      0.70      0.78        70\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       123\n",
      "   macro avg       0.53      0.55      0.53       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      " samples avg       0.78      0.78      0.78       123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.94      0.58        54\n",
      "           1       0.54      0.84      0.66        76\n",
      "           2       0.00      0.00      0.00       110\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       240\n",
      "   macro avg       0.32      0.60      0.41       240\n",
      "weighted avg       0.27      0.48      0.34       240\n",
      " samples avg       0.48      0.48      0.48       240\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87        88\n",
      "           1       0.78      0.62      0.69        29\n",
      "           2       0.49      1.00      0.66        20\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       137\n",
      "   macro avg       0.74      0.81      0.74       137\n",
      "weighted avg       0.85      0.79      0.80       137\n",
      " samples avg       0.79      0.79      0.79       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88       105\n",
      "           1       0.46      1.00      0.63        27\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       141\n",
      "   macro avg       0.49      0.59      0.50       141\n",
      "weighted avg       0.83      0.77      0.77       141\n",
      " samples avg       0.77      0.77      0.77       141\n",
      "\n",
      "acc:  0.6472958959940414 \n",
      " f1:  0.5970768336819037 \n",
      " balanced_acc:  0.6473737743676713\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for evaluation\n",
    "!!!!!!!!\n",
    "!!!!!!!\n",
    "!!!!!\n",
    "!!!!\n",
    "!!\n",
    "!\n",
    "\n",
    "\"\"\"\n",
    "seed(0)\n",
    "# keras seed\n",
    "set_seed(0)\n",
    "#features_new = np.expand_dims(features_new, axis=-1).astype(float)\n",
    "#%%\n",
    "          \n",
    "NN = True\n",
    "if NN:\n",
    "    predict = True\n",
    "    save_model_path = './models_resample/'\n",
    "    batch_size = 16\n",
    "    lppo = LeavePGroupsOut(n_groups=1)\n",
    "    #lppo = GroupKFold(n_splits=2)\n",
    "    #kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)\n",
    "    fold_no = 1\n",
    "    f1_per_fold, acc_per_fold, pre_per_fold, rec_per_fold, balanced_acc_per_fold = [], [], [], [], []\n",
    "    # training\n",
    "    if not predict:\n",
    "        #for train, test in kfold.split(features, labels):\n",
    "        for train, test in lppo.split(features_new, labels_new, groups_new):\n",
    "            feat_train, labels_train = features_new[train], labels_new[train]\n",
    "            feat_test, labels_test = features_new[test], labels_new[test]\n",
    "            feat_train = format_input(feat_train)\n",
    "            feat_test = format_input(feat_test)\n",
    "            labels_train = np_utils.to_categorical(labels_train)\n",
    "            labels_test = np_utils.to_categorical(labels_test)\n",
    "            model_fold = model_nn(input_shape=(25, 40, 1)).model()\n",
    "            # Fit data to model, only models with the best val acc (unbalanced) are saved\n",
    "            model_fold.fit(feat_train, labels_train,\n",
    "                           batch_size=batch_size,\n",
    "                           epochs=5,\n",
    "                           validation_data=(feat_test, labels_test),\n",
    "                           verbose=2,\n",
    "                           callbacks=[K.callbacks.ModelCheckpoint(save_model_path+\"fold%01d-epoch_{epoch:02d}-acc_{val_categorical_accuracy:.4f}.h5\" %fold_no, \n",
    "                                                                  monitor='val_categorical_accuracy', \n",
    "                                                                  verbose=0, \n",
    "                                                                  save_best_only=True, \n",
    "                                                                  save_weights_only=True, \n",
    "                                                                  mode='auto', \n",
    "                                                                  save_freq='epoch')])\n",
    "            del model_fold\n",
    "            fold_no = fold_no + 1\n",
    "    # validation                     \n",
    "    if predict:\n",
    "        models = sorted([os.path.join(save_model_path, item) \\\n",
    "                         for item in os.listdir(save_model_path) if item.endswith('.h5')], key=last_4chars)\n",
    "        #for train, test in kfold.split(features, labels):\n",
    "        for train, test in lppo.split(features_new, labels_new, groups=groups_new):\n",
    "#             feat_train, labels_train = features_new[train], labels_new[train]\n",
    "            feat_test, labels_test = features_new[test], labels_new[test]\n",
    "            feat_test = format_input(feat_test)\n",
    "            labels_test = np_utils.to_categorical(labels_test)\n",
    "            model_pred = model_nn(input_shape=(25, 40, 1)).model()\n",
    "            model_pred.load_weights(models[fold_no - 1])\n",
    "            # prediction\n",
    "            pred_prob = model_pred.predict(feat_test)\n",
    "#             pred_prob = pred_prob.argmax(axis=1)\n",
    "            result = []\n",
    "            for i in pred_prob:\n",
    "                temp = i.argmax(axis=0)\n",
    "                if temp == 0:\n",
    "                    result.append([1,0,0])\n",
    "                elif temp == 1:\n",
    "                    result.append([0,1,0])\n",
    "                else:\n",
    "                    result.append([0,0,1])\n",
    "            result = np.asarray(result, dtype=np.int)\n",
    "#             print(np.argsort(pred_prob,axis=1))\n",
    "#             break\n",
    "#             acc_per_fold.append(balanced_accuracy_score(labels_test, pred_prob) * 100)\n",
    "#             f1_per_fold.append(f1_score(labels_test, pred_prob, average = 'macro') * 100) \n",
    "            f1_per_fold.append(f1_score(labels_test, result,average='weighted'))\n",
    "            acc_per_fold.append(accuracy_score(labels_test, result))\n",
    "            balanced_acc_per_fold.append(balanced_accuracy_score([np.argmax(one_hot)for one_hot in labels_test],[np.argmax(one_hot)for one_hot in result]))\n",
    "            print(classification_report(labels_test,result))\n",
    "            # initialize\n",
    "            del model_pred\n",
    "            fold_no = fold_no + 1\n",
    "        f1 = np.mean(f1_per_fold)\n",
    "        acc = np.mean(acc_per_fold)\n",
    "        balanced_acc = np.mean(balanced_acc_per_fold)\n",
    "        print('acc: ', acc, '\\n f1: ', f1, '\\n balanced_acc: ', balanced_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,figsize=(10,10))\n",
    "plt.spy(merged_test[:,:-1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'b': 11008, 't': 8641, '1': 7211, '2': 4988, 'p': 1141, 'm': 1111, 'c': 642, 'x': 517})\n",
      "Counter({'t': 2350, 'b': 2095, '1': 1615, '2': 370, 'p': 132, 'm': 91, 'x': 19})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(merged_train[:,-1]))\n",
    "print(Counter(merged_test[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap_merged_data(merged_train):\n",
    "    train_class = Counter(merged_train[:,-1])\n",
    "    resample_train = []\n",
    "    for i in train_class:\n",
    "        temp_data = merged_train[merged_train[:,-1]==i]\n",
    "        temp_data = resample(temp_data, n_samples=6000, random_state=0)\n",
    "        if len(resample_train) == 0:\n",
    "            resample_train = temp_data\n",
    "        else:\n",
    "            resample_train = np.r_[resample_train,temp_data]\n",
    "    return resample_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_train = boostrap_merged_data(merged_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample_train_X = coo_matrix(resample_train[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(max_depth=10, random_state=0)).fit(resample_train[:,:-1], resample_train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.69      0.54      6000\n",
      "           2       0.36      0.18      0.24      6000\n",
      "           b       0.47      0.86      0.61      6000\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.40      0.16      0.23      6000\n",
      "           p       0.38      0.18      0.25      6000\n",
      "           t       0.37      0.73      0.49      6000\n",
      "           x       0.36      0.05      0.09      6000\n",
      "\n",
      "    accuracy                           0.41     42000\n",
      "   macro avg       0.35      0.35      0.30     42000\n",
      "weighted avg       0.40      0.41      0.35     42000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resample_test_pred = clf.predict(resample_test[:,:-1])\n",
    "print(classification_report(resample_test[:,-1],resample_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lopo_count(data, standard):\n",
    "    \"\"\"\n",
    "    parms:\n",
    "    data: could be one of train_data and test_data\n",
    "    standard: same as bivar_transform\n",
    "    return: tuple contains the number of two labels (standard and 'other')\n",
    "    \"\"\"\n",
    "    standard_count, other_count = 0, 0\n",
    "    for i in data:\n",
    "        count = Counter(data[i][:,-1])\n",
    "        if len(count) == 2:\n",
    "            other_count += count['other']\n",
    "            standard_count += count[standard]\n",
    "        else:\n",
    "            other_count += count['other']\n",
    "    return standard_count, other_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-be0bada80baa>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cp.iloc[:,-1][i] = temp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train_data: 1050 'm' 34236 'other' \n",
      "In test_data: 152 'm' 6493 'other' \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " 'm'  p7 \n",
    "\"\"\"\n",
    "train_data, test_data = lopo(p=6, standard='m')\n",
    "m_count_train, other_count_train = lopo_count(train_data, standard='m')\n",
    "m_count_test, other_count_test = lopo_count(test_data, standard='m')\n",
    "print('In train_data: ' + str(m_count_train) + \" 'm' \" + str(other_count_train) + \" 'other' \")\n",
    "print('In test_data: ' + str(m_count_test) + \" 'm' \" + str(other_count_test) + \" 'other' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6,rfadaboost\n",
    "\"\"\"\n",
    "def model_dict(data, model: str):\n",
    "    \"\"\"\n",
    "    parms:\n",
    "    model: model in ['rf','adaboost']\n",
    "    \"\"\"\n",
    "    model_dict = dict()\n",
    "    if model == 'rf':\n",
    "        for i in data:\n",
    "            rfc = RandomForestClassifier(max_depth=30, random_state=0) #max_depth ~ sqrt(n_features=1000)\n",
    "            rfc.fit(data[i][:,:-1],data[i][:,-1])\n",
    "            model_dict[i] = rfc\n",
    "    elif model == 'adaboost':\n",
    "        for i in data:\n",
    "            ada = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "            ada.fit(data[i][:,:-1],data[i][:,-1])\n",
    "            model_dict[i] = ada\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_rf = model_dict(train_data, model='rf')\n",
    "# model_dict_ada = model_dict(train_data, model='adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for outdoor.csv\n",
      "rf 0.9699812382739212\n",
      "\n",
      "\n",
      "score for reading.csv\n",
      "rf 1.0\n",
      "\n",
      "\n",
      "score for call.csv\n",
      "rf 1.0\n",
      "\n",
      "\n",
      "score for dinner.csv\n",
      "rf 0.9930887825624668\n",
      "\n",
      "\n",
      "score for game.csv\n",
      "rf 0.9251412429378532\n",
      "\n",
      "\n",
      "score for TV.csv\n",
      "rf 0.9867549668874173\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "rf/adaboost as the baseline and calculate the score for test_data\n",
    "\"\"\"\n",
    "for i in test_data:\n",
    "    print('score for ' + i)\n",
    "    print('rf',model_dict_rf[i].score(test_data[i][:,:-1],test_data[i][:,-1]))\n",
    "#     print('adaboost',model_dict_ada[i].score(test_data[i][:,:-1],test_data[i][:,-1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report for outdoor.csv\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           m       0.00      0.00      0.00        16\n",
      "       other       0.97      1.00      0.98       517\n",
      "\n",
      "    accuracy                           0.97       533\n",
      "   macro avg       0.48      0.50      0.49       533\n",
      "weighted avg       0.94      0.97      0.96       533\n",
      "\n",
      "\n",
      "\n",
      "report for reading.csv\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       1.00      1.00      1.00       226\n",
      "\n",
      "    accuracy                           1.00       226\n",
      "   macro avg       1.00      1.00      1.00       226\n",
      "weighted avg       1.00      1.00      1.00       226\n",
      "\n",
      "\n",
      "\n",
      "report for call.csv\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       1.00      1.00      1.00       406\n",
      "\n",
      "    accuracy                           1.00       406\n",
      "   macro avg       1.00      1.00      1.00       406\n",
      "weighted avg       1.00      1.00      1.00       406\n",
      "\n",
      "\n",
      "\n",
      "report for dinner.csv\n",
      "rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           m       0.00      0.00      0.00        26\n",
      "       other       0.99      1.00      1.00      3736\n",
      "\n",
      "    accuracy                           0.99      3762\n",
      "   macro avg       0.50      0.50      0.50      3762\n",
      "weighted avg       0.99      0.99      0.99      3762\n",
      "\n",
      "\n",
      "\n",
      "report for game.csv\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           m       0.00      0.00      0.00       106\n",
      "       other       0.93      1.00      0.96      1310\n",
      "\n",
      "    accuracy                           0.93      1416\n",
      "   macro avg       0.46      0.50      0.48      1416\n",
      "weighted avg       0.86      0.93      0.89      1416\n",
      "\n",
      "\n",
      "\n",
      "report for TV.csv\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           m       0.00      0.00      0.00         4\n",
      "       other       0.99      1.00      0.99       298\n",
      "\n",
      "    accuracy                           0.99       302\n",
      "   macro avg       0.49      0.50      0.50       302\n",
      "weighted avg       0.97      0.99      0.98       302\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in test_data:\n",
    "    print('report for ' + i)\n",
    "    print('rf')\n",
    "    print(classification_report(test_data[i][:,-1],model_dict_rf[i].predict(test_data[i][:,:-1])))\n",
    "#     print('rf',model_dict_rf[i].score(test_data[i][:,:-1],test_data[i][:,-1]))\n",
    "#     print('adaboost',model_dict_ada[i].score(test_data[i][:,:-1],test_data[i][:,-1]))\n",
    "#     print('adaboost')\n",
    "#     print(classification_report(test_data[i][:,-1],model_dict_ada[i].predict(test_data[i][:,:-1])))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "rf/adaboost. \n",
    "\"\"\"\n",
    "main_path = os.getcwd()\n",
    "dir_list = os.listdir(os.path.join(main_path,'p1'))\n",
    "original_data = {}\n",
    "main_list = ['p'+str(i) for i in range(1,7)]\n",
    "for i in main_list:\n",
    "    for j in dir_list:\n",
    "        d = pd.read_csv(os.path.join(main_path,i,j),low_memory=False)\n",
    "        d = np.array(d)\n",
    "        if original_data.get(j) is None:\n",
    "            original_data[j] = d\n",
    "        else:\n",
    "            original_data[j] = np.r_[original_data[j],d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test_data = dict()\n",
    "for i in dir_list:\n",
    "    d = pd.read_csv(os.path.join(main_path,'p7',i),low_memory=False)\n",
    "    d = np.array(d)\n",
    "    original_test_data[i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_dict = dict()\n",
    "for i in data:\n",
    "    rfc = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "    rfc.fit(original_data[i][:,:-1],original_data[i][:,-1])\n",
    "    original_model_dict[i] = rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " outdoor.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       273\n",
      "           2       0.28      0.31      0.29       100\n",
      "           b       0.86      0.87      0.86       284\n",
      "           m       0.00      0.00      0.00        26\n",
      "           x       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.70       684\n",
      "   macro avg       0.37      0.38      0.38       684\n",
      "weighted avg       0.68      0.70      0.69       684\n",
      "\n",
      "\n",
      " reading.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.99      0.98       213\n",
      "           b       0.86      0.67      0.75        18\n",
      "\n",
      "    accuracy                           0.97       231\n",
      "   macro avg       0.91      0.83      0.87       231\n",
      "weighted avg       0.96      0.97      0.96       231\n",
      "\n",
      "\n",
      " call.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.98      0.94       336\n",
      "           b       0.00      0.00      0.00        23\n",
      "           m       0.00      0.00      0.00        23\n",
      "           p       0.80      0.94      0.86       125\n",
      "\n",
      "    accuracy                           0.88       507\n",
      "   macro avg       0.43      0.48      0.45       507\n",
      "weighted avg       0.80      0.88      0.84       507\n",
      "\n",
      "\n",
      " dinner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.69      0.79       557\n",
      "           2       0.39      0.38      0.39       198\n",
      "           b       0.70      0.94      0.81      1462\n",
      "           m       0.00      0.00      0.00        18\n",
      "           p       0.00      0.00      0.00         7\n",
      "           t       0.73      0.48      0.58       922\n",
      "           x       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.72      3177\n",
      "   macro avg       0.39      0.36      0.37      3177\n",
      "weighted avg       0.72      0.72      0.70      3177\n",
      "\n",
      "\n",
      " game.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.82      0.77       201\n",
      "           2       0.59      0.57      0.58        72\n",
      "           b       0.90      0.91      0.90       278\n",
      "           m       0.00      0.00      0.00        24\n",
      "           t       0.00      0.00      0.00         0\n",
      "           x       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79       580\n",
      "   macro avg       0.37      0.38      0.37       580\n",
      "weighted avg       0.75      0.79      0.77       580\n",
      "\n",
      "\n",
      " TV.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.23      0.37        35\n",
      "           2       0.00      0.00      0.00         0\n",
      "           b       0.38      0.10      0.16        30\n",
      "           t       0.97      1.00      0.98      1428\n",
      "\n",
      "    accuracy                           0.96      1493\n",
      "   macro avg       0.59      0.33      0.38      1493\n",
      "weighted avg       0.96      0.96      0.95      1493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in original_test_data:\n",
    "    temp_data = original_test_data[i]\n",
    "    print(\"\\n\",i)\n",
    "    y_pred = original_model_dict[i].predict(temp_data[:,:-1]) \n",
    "    print(classification_report(original_test_data[i][:,-1],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoor.csv\n",
      "Counter({'b': 791, '1': 768, '2': 746, 'm': 179, 'x': 125, 'c': 82})\n",
      "Counter({'b': 284, '1': 273, '2': 100, 'm': 26, 'x': 1})\n",
      "\n",
      "\n",
      "reading.csv\n",
      "Counter({'1': 1084, 'b': 138, 'x': 5, '2': 1, 'm': 1})\n",
      "Counter({'1': 213, 'b': 18})\n",
      "\n",
      "\n",
      "call.csv\n",
      "Counter({'p': 1112, '1': 973, 'b': 142, 'm': 129, 'c': 13, '2': 5})\n",
      "Counter({'1': 336, 'p': 125, 'b': 23, 'm': 23})\n",
      "\n",
      "\n",
      "dinner.csv\n",
      "Counter({'b': 8191, 't': 5634, '2': 3056, '1': 2236, 'm': 430, 'c': 404, 'x': 323, 'p': 29})\n",
      "Counter({'b': 1462, 't': 922, '1': 557, '2': 198, 'm': 18, 'x': 13, 'p': 7})\n",
      "\n",
      "\n",
      "game.csv\n",
      "Counter({'1': 1905, 'b': 1544, '2': 896, 'm': 343, 't': 281, 'c': 62, 'x': 39})\n",
      "Counter({'b': 278, '1': 201, '2': 72, 'm': 24, 'x': 5})\n",
      "\n",
      "\n",
      "TV.csv\n",
      "Counter({'t': 2726, '2': 284, '1': 245, 'b': 202, 'c': 81, 'm': 29, 'x': 25})\n",
      "Counter({'t': 1428, '1': 35, 'b': 30})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train/test\n",
    "\"\"\"\n",
    "for i in original_test_data:\n",
    "    print(i)\n",
    "    print(Counter(original_data[i][:,-1]))\n",
    "    print(Counter(original_test_data[i][:,-1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_adaboost_dict = dict()\n",
    "for i in data:\n",
    "    rfc = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "    rfc.fit(original_data[i][:,:-1],original_data[i][:,-1])\n",
    "    original_adaboost_dict[i] = rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " outdoor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.61      0.64       273\n",
      "           2       0.07      0.06      0.07       100\n",
      "           b       0.76      0.86      0.81       284\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.13      0.12      0.12        26\n",
      "           x       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       684\n",
      "   macro avg       0.27      0.27      0.27       684\n",
      "weighted avg       0.60      0.61      0.61       684\n",
      "\n",
      "\n",
      " reading.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.99      0.98       213\n",
      "           b       0.87      0.72      0.79        18\n",
      "\n",
      "    accuracy                           0.97       231\n",
      "   macro avg       0.92      0.86      0.89       231\n",
      "weighted avg       0.97      0.97      0.97       231\n",
      "\n",
      "\n",
      " call.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.98      0.93       336\n",
      "           b       0.00      0.00      0.00        23\n",
      "           m       0.00      0.00      0.00        23\n",
      "           p       0.80      0.87      0.83       125\n",
      "\n",
      "    accuracy                           0.86       507\n",
      "   macro avg       0.42      0.46      0.44       507\n",
      "weighted avg       0.78      0.86      0.82       507\n",
      "\n",
      "\n",
      " dinner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       557\n",
      "           2       0.20      0.16      0.18       198\n",
      "           b       0.69      0.86      0.77      1462\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.05      0.11      0.07        18\n",
      "           p       0.00      0.00      0.00         7\n",
      "           t       0.64      0.50      0.56       922\n",
      "           x       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.66      3177\n",
      "   macro avg       0.30      0.28      0.28      3177\n",
      "weighted avg       0.66      0.66      0.65      3177\n",
      "\n",
      "\n",
      " game.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.32      0.41       201\n",
      "           2       0.58      0.31      0.40        72\n",
      "           b       0.85      0.78      0.81       278\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.09      0.46      0.15        24\n",
      "           t       0.00      0.00      0.00         0\n",
      "           x       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.54       580\n",
      "   macro avg       0.29      0.27      0.25       580\n",
      "weighted avg       0.67      0.54      0.59       580\n",
      "\n",
      "\n",
      " TV.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.37      0.51        35\n",
      "           2       0.00      0.00      0.00         0\n",
      "           b       0.01      0.03      0.02        30\n",
      "           c       0.00      0.00      0.00         0\n",
      "           m       0.00      0.00      0.00         0\n",
      "           t       0.97      0.94      0.96      1428\n",
      "           x       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91      1493\n",
      "   macro avg       0.26      0.19      0.21      1493\n",
      "weighted avg       0.95      0.91      0.93      1493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in original_test_data:\n",
    "    temp_data = original_test_data[i]\n",
    "    print(\"\\n\",i)\n",
    "    y_pred = original_adaboost_dict[i].predict(temp_data[:,:-1]) \n",
    "    print(classification_report(original_test_data[i][:,-1],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/cleanlab/pruning.py:38: UserWarning: If you want to see estimated completion times\n",
      "    while running methods in cleanlab.pruning, install tqdm\n",
      "    via \"pip install tqdm\".\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " cleanlab \n",
    "[6] train/test label\n",
    "label(1)split,bug\n",
    "\n",
    "[]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "outdoor.csv\n",
    "traintesttestlabeltest '1'\n",
    "\"\"\"\n",
    "from cleanlab.classification import LearningWithNoisyLabels\n",
    "temp_data = original_data['outdoor.csv']\n",
    "temp_test = original_test_data['outdoor.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_convert(value):\n",
    "    if value == '1':\n",
    "        return 0\n",
    "    elif value == '2':\n",
    "        return 1\n",
    "    elif value == 'b':\n",
    "        return 2\n",
    "    elif value == 'c':\n",
    "        return 3\n",
    "    elif value == 'm':\n",
    "        return 4\n",
    "    elif value == 'x':\n",
    "        return 5\n",
    "\n",
    "def temp_transform(data):\n",
    "    data_cp = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        temp = temp_convert(data[:,-1][i])\n",
    "        data_cp[:,-1][i] = temp\n",
    "    return data_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_transform(temp_data)\n",
    "temp_test = temp_transform(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_X = np.array(temp_data[:,:-1],dtype=np.float)\n",
    "temp_data_Y = np.array(temp_data[:,-1],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test_X = np.array(temp_test[:,:-1],dtype=np.float)\n",
    "temp_test_Y = np.array(temp_test[:,-1],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\n",
    "lnl = LearningWithNoisyLabels(clf=RandomForestClassifier(max_depth=30,random_state=0))\n",
    "lnl.fit(X=temp_data_X, s=temp_data_Y)\n",
    "# .\n",
    "predicted_test_labels = lnl.predict(temp_test_X)\n",
    "# print(classification_report(temp_test_Y,predicted_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "psx = cleanlab.latent_estimation.estimate_cv_predicted_probabilities(\n",
    "    temp_data_X, temp_data_Y, clf=RandomForestClassifier(max_depth=30, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.pruning import get_noise_indices\n",
    "psx = np.asarray(psx)\n",
    "ordered_label_errors = get_noise_indices(\n",
    "    s=temp_data_Y,\n",
    "    psx=psx,\n",
    "    sorted_index_method='normalized_margin', # Orders label errors\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_data = np.array(list(range(len(temp_data_X))))\n",
    "index_list_test = np.array(list(range(len(temp_test_X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_index_list_data = []\n",
    "for i in index_list_data:\n",
    "    if i in ordered_label_errors:\n",
    "        cp_index_list_data.append(False)\n",
    "    else:\n",
    "        cp_index_list_data.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 589, 1: 618, 2: 695, 4: 69, 5: 36, 3: 29})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(temp_data_Y[cp_index_list_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 768, 1: 746, 2: 791, 4: 179, 5: 125, 3: 82})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(temp_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, random_state=0)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "rfc.fit(temp_data_X[cp_index_list_data,:],temp_data_Y[cp_index_list_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-fd86699078a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m psx_test = cleanlab.latent_estimation.estimate_cv_predicted_probabilities(\n\u001b[0m\u001b[1;32m      5\u001b[0m     temp_test_X, temp_test_Y, clf=RandomForestClassifier(max_depth=30, random_state=0,min_samples_split=1))\n\u001b[1;32m      6\u001b[0m \u001b[0mpsx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_cv_predicted_probabilities\u001b[0;34m(X, labels, clf, cv_n_folds, seed)\u001b[0m\n\u001b[1;32m    739\u001b[0m         should have been computed using 3 (or higher) fold cross-validation.\"\"\"\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m     return estimate_py_noise_matrices_and_cv_pred_proba(\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_py_noise_matrices_and_cv_pred_proba\u001b[0;34m(X, s, clf, cv_n_folds, thresholds, converge_latent_estimates, py_method, seed)\u001b[0m\n\u001b[1;32m    679\u001b[0m       joint count matrix i.e. confident joint, predicted probability matrix)\"\"\"\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m     confident_joint, psx = estimate_confident_joint_and_cv_pred_proba(\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/cleanlab/latent_estimation.py\u001b[0m in \u001b[0;36mestimate_confident_joint_and_cv_pred_proba\u001b[0;34m(X, s, clf, cv_n_folds, thresholds, seed, calibrate)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# Fit the clf classifier to the training set and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# predict on the holdout set and update psx.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mclf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0mpsx_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_holdout_cv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# P(s = k|x) # [:,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mpsx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcv_holdout_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsx_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 raise ValueError(\"min_samples_split must be an integer \"\n\u001b[0m\u001b[1;32m    229\u001b[0m                                  \u001b[0;34m\"greater than 1 or a float in (0.0, 1.0]; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                                  \u001b[0;34m\"got the integer %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test(labeltest) \n",
    "\"\"\"\n",
    "psx_test = cleanlab.latent_estimation.estimate_cv_predicted_probabilities(\n",
    "    temp_test_X, temp_test_Y, clf=RandomForestClassifier(max_depth=30, random_state=0))\n",
    "psx_test = np.asarray(psx_test)\n",
    "ordered_label_errors_test = get_noise_indices(\n",
    "    s=temp_test_Y,\n",
    "    psx=psx_test,\n",
    "    sorted_index_method='normalized_margin', # Orders label errors\n",
    " )\n",
    "cp_index_list_test = []\n",
    "for i in index_list_test:\n",
    "    if i in ordered_label_errors_test:\n",
    "        cp_index_list_test.append(False)\n",
    "    else:\n",
    "        cp_index_list_test.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       273\n",
      "           1       0.26      0.35      0.30       100\n",
      "           2       0.87      0.87      0.87       284\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69       684\n",
      "   macro avg       0.37      0.38      0.38       684\n",
      "weighted avg       0.69      0.69      0.69       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "()\n",
    "https://github.com/cgnorthcutt/cleanlab/blob/master/examples/simplifying_confident_learning_tutorial.ipynb\n",
    "\"\"\"\n",
    "temp_test_Y_pred = rfc.predict(temp_test_X)\n",
    "print(classification_report(temp_test_Y,temp_test_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit9755afc1b5134399b36eeb8f9d660dbb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
